path_SY="C:/Users/s.yaspo/Dropbox/Smart Pooling and Pruning/Package/TVA"
setwd(path_SY)
document()
#Install the actual package
install_github('SimonYFR/TVA')
library('TVA')
# pval one-step elimination
result = do_TVA(data = data, arms = arms, fes = fes, y = y, cutoff = 1 * 10^(-8), w = w, estimation_function_name = 'pval_OSE', scale = FALSE, compare_to_zero = FALSE)
result$data
result$data %>% sample(20)
result$data %>% sample(20)
result$data %>% sample(.,20)
result$data$pool_influences_list %>% sample(20)
result$data$pool_influences_list %>% sample(20)
#document
path_SY="C:/Users/s.yaspo/Dropbox/Smart Pooling and Pruning/Package/TVA"
setwd(path_SY)
document()
#Install the actual package
install_github('SimonYFR/TVA')
library('TVA')
# pval one-step elimination
result = do_TVA(data = data, arms = arms, fes = fes, y = y, cutoff = 1 * 10^(-8), w = w, estimation_function_name = 'pval_OSE', scale = FALSE, compare_to_zero = FALSE)
result$data
result$data . tail(Ã )
result$data %>% tail()
result$data
result$data %>% sample(nrow(.),20)
result$data[sample(nrow(result$data),20)]
result$data[sample(nrow(result$data),20),]
result$data[sample(nrow(result$data),20),c('pool_influences','pool_influences_list')]
result$data[sample(nrow(result$data),20),c('pool_influences','pool_influences_list')]
result$data[sample(nrow(result$data),20),c('pool_influences','pool_influences_list')]
result$data[sample(nrow(result$data),20),c('pool_influences','pool_influences_list')]
result$data[sample(nrow(result$data),20),c('pool_influences','pool_influences_list')]
result$data[sample(nrow(result$data),20),c('pool_influences','pool_influences_list')]
result$data[sample(nrow(result$data),20),c('pool_influences','pool_influences_list')]
result$data[sample(nrow(result$data),20),c('pool_influences','pool_influences_list')]
result$data[sample(nrow(result$data),20),c('pool_influences','pool_influences_list')]
result$data[sample(nrow(result$data),220),c('pool_influences','pool_influences_list')]
result$marginal_support
result$pools_summary
result$unique_policy
#document
path_SY="C:/Users/s.yaspo/Dropbox/Smart Pooling and Pruning/Package/TVA"
setwd(path_SY)
document()
#Install the actual package
install_github('SimonYFR/TVA')
library('TVA')
# pval one-step elimination
result = do_TVA(data = data, arms = arms, fes = fes, y = y, cutoff = 1 * 10^(-8), w = w, estimation_function_name = 'pval_OSE', scale = FALSE, compare_to_zero = FALSE)
result$pools_summary
result$unique_policy
result$pools_summary
#document
path_SY="C:/Users/s.yaspo/Dropbox/Smart Pooling and Pruning/Package/TVA"
setwd(path_SY)
document()
#Install the actual package
install_github('SimonYFR/TVA')
library('TVA')
# pval one-step elimination
result = do_TVA(data = data, arms = arms, fes = fes, y = y, cutoff = 1 * 10^(-8), w = w, estimation_function_name = 'pval_OSE', scale = FALSE, compare_to_zero = FALSE)
c=('huj','hjkh')
cat(c)
c=c('huj','hjkh')
cat(c)
cat(c,"\n")
#document
path_SY="C:/Users/s.yaspo/Dropbox/Smart Pooling and Pruning/Package/TVA"
setwd(path_SY)
document()
result$marginal_support
result$pools_summary
reminder = c(0,1,2) %>% sample(.,5)
reminder = c(0,1,2) %>% sample(.,replace=TRUE, 5)
reminder
n_obs = 1000
reminder = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(reminder=reminder, incentive=incentive, information=information )
df
df$outcome = 0
df
TRUE & TRUE
df[df$information == 0 & df$incentive >=0 ]
df[ (df$information == 0) & (df$incentive >=0) ]
df[, (df$information == 0) & (df$incentive >=0) ]
df[(df$information == 0) & (df$incentive >=0), ]
df[(df$information == 0) & (df$incentive >=1), ]
df[(df$information == 0) & (df$incentive >=1)]
df[(df$information == 0) & (df$incentive >=1),]
df[(df$information == 0) & (df$incentive >=1),'outcome']
n_obs = 1000
reminder = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, reminder=reminder, incentive=incentive, information=information )
df
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive  =1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive  =2),'outcome'] = 4.5
df
n_obs = 1000
reminder = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, reminder=reminder, incentive=incentive, information=information )
df
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df
rnorm(0,0.3)
rnorm(0,0.3,1)
rnorm(10, mean = 0 , sd = 0.3)
reminder = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=rnorm(n_obs, mean = 0 , sd = 0.3), reminder=reminder, incentive=incentive, information=information )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df
df = data.frame(outcome=rnorm(n_obs, mean = 0 , sd = 0.3), reminder=reminder, incentive=incentive, information=information )
df[(df$information == 0) & (df$incentive >=1),'outcome'] += 1
n_obs = 1000
reminder = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, reminder=reminder, incentive=incentive, information=information )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 0.3)
df
formula <- as.formula("outcome ~ reminder + incentive + information")
current_model_ols <- estimatr::lm_robust(formula = formula, data = df)
OLS <- estimatr::lm_robust(formula = formula, data = df)
OLS
as.numeric(factor(paste0(df$reminder, df$incentive, df$information)))
n_obs = 1000
reminder = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, reminder=reminder, incentive=incentive, information=information )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 0.3)
df$unique_policy_id = as.numeric(factor(paste0(df$reminder, df$incentive, df$information)))
unique_policy_dummies <- data.frame(lme4::dummy(df$unique_policy_id))
unique_policy_dummies
df <- cbind(df, unique_policy_dummies)
df
unique_policies = names(unique_policy_dummies)
unique_policies
as.formula(paste0("outcome","~",paste0(unique_policies,collapse = "+")))
n_obs = 1000
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
age = c(0,1) %>% sample(.,replace=TRUE, n_obs)
year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information, age=age, year=year )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 0.3)
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
unique_policies = names(unique_policy_dummies)
df = cbind(df, unique_policy_dummies)
as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
formula <- as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS <- estimatr::lm_robust(formula = formula, data = df)
OLS
n_obs = 1000
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
age = c(0,1) %>% sample(.,replace=TRUE, n_obs)
year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information, age=age, year=year )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 1)
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
unique_policies = names(unique_policy_dummies)
df = cbind(df, unique_policy_dummies)
formula <- as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS <- estimatr::lm_robust(formula = formula, data = df)
OLS
n_obs = 500
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
age = c(0,1) %>% sample(.,replace=TRUE, n_obs)
year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information, age=age, year=year )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 1)
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
unique_policies = names(unique_policy_dummies)
df = cbind(df, unique_policy_dummies)
formula <- as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS <- estimatr::lm_robust(formula = formula, data = df)
OLS
n_obs = 500
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
age = c(0,1) %>% sample(.,replace=TRUE, n_obs)
year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information, age=age, year=year )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df[df$year == 1]$outcome = df[df$year == 1]$outcome + 2
df[df$age  == 1]$outcome = df[df$age  == 1]$outcome + 1
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 1)
n_obs = 500
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
age = c(0,1) %>% sample(.,replace=TRUE, n_obs)
year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information, age=age, year=year )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df[df$year == 1,'outcome'] = df[df$year == 1,'outcome'] + 2
df[df$age  == 1,'outcome'] = df[df$age  == 1,'outcome'] + 1
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 1)
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
unique_policies = names(unique_policy_dummies)
df = cbind(df, unique_policy_dummies)
formula <- as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS <- estimatr::lm_robust(formula = formula, data = df)
OLS
n_obs = 200
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
age = c(0,1) %>% sample(.,replace=TRUE, n_obs)
year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information, age=age, year=year )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df[df$year == 1,'outcome'] = df[df$year == 1,'outcome'] + 2
df[df$age  == 1,'outcome'] = df[df$age  == 1,'outcome'] + 1
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 1)
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
unique_policies = names(unique_policy_dummies)
df = cbind(df, unique_policy_dummies)
formula <- as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS <- estimatr::lm_robust(formula = formula, data = df)
OLS
n_obs = 1000
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
age = c(0,1) %>% sample(.,replace=TRUE, n_obs)
year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information, age=age, year=year )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df[df$year == 1,'outcome'] = df[df$year == 1,'outcome'] + 2
df[df$age  == 1,'outcome'] = df[df$age  == 1,'outcome'] + 1
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 2)
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
unique_policies = names(unique_policy_dummies)
df = cbind(df, unique_policy_dummies)
formula <- as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS <- estimatr::lm_robust(formula = formula, data = df)
OLS
n_obs = 1000
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
age = c(0,1) %>% sample(.,replace=TRUE, n_obs)
year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information, age=age, year=year )
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
df[df$year == 1,'outcome'] = df[df$year == 1,'outcome'] + 2
df[df$age  == 1,'outcome'] = df[df$age  == 1,'outcome'] + 1
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 4)
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
unique_policies = names(unique_policy_dummies)
df = cbind(df, unique_policy_dummies)
formula <- as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS <- estimatr::lm_robust(formula = formula, data = df)
OLS
arms = c('sms','incentive','information')
fes = c('year','age')
y = 'outcome'
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.05 )
#document
path_SY="C:/Users/s.yaspo/Dropbox/Smart Pooling and Pruning/Package/TVA"
setwd(path_SY)
document()
#Install the actual package
install_github('SimonYFR/TVA')
library('TVA')
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.05 )
#document
path_SY="C:/Users/s.yaspo/Dropbox/Smart Pooling and Pruning/Package/TVA"
setwd(path_SY)
document()
#Install the actual package
install_github('SimonYFR/TVA')
library('TVA')
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.05 )
result$data
result$pools_summary
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.005 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.01 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.02 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.05 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.045 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.04 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.043 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.042 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.041 )
result$marginal_support
grid_pval_OSE(data=df,arms=arms,fes=fes,y=y)
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.041 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.0415 )
result$marginal_support
#simulate observations
n_obs = 1000
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information )
#define the true outcome
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
#add random noise
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 2)
#fixed effects
df$year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df$age  = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df[df$year == 1,'outcome'] = df[df$year == 1,'outcome'] + 2
df[df$age  == 1,'outcome'] = df[df$age  == 1,'outcome'] + 1
#unique policy space
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
df = cbind(df, unique_policy_dummies)
#simple OLS
unique_policies = names(unique_policy_dummies)
formula = as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS = estimatr::lm_robust(formula = formula, data = df)
arms = c('sms','incentive','information')
fes = c('year','age')
y = 'outcome'
grid_pval_OSE(data=df,arms=arms,fes=fes,y=y)
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.05 )
result$marginal_support
#simulate observations
n_obs = 1000
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information )
#define the true outcome
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
#add random noise
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 1)
#fixed effects
df$year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df$age  = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df[df$year == 1,'outcome'] = df[df$year == 1,'outcome'] + 2
df[df$age  == 1,'outcome'] = df[df$age  == 1,'outcome'] + 1
#unique policy space
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
df = cbind(df, unique_policy_dummies)
#simple OLS
unique_policies = names(unique_policy_dummies)
formula = as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS = estimatr::lm_robust(formula = formula, data = df)
arms = c('sms','incentive','information')
fes = c('year','age')
y = 'outcome'
grid_pval_OSE(data=df,arms=arms,fes=fes,y=y)
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.05 )
result$marginal_support
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.005 )
result$marginal_support
OLS
#simulate observations
n_obs = 1000
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information )
#define the true outcome
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
#add random noise
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 2)
#fixed effects
df$year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df$age  = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df[df$year == 1,'outcome'] = df[df$year == 1,'outcome'] + 2
df[df$age  == 1,'outcome'] = df[df$age  == 1,'outcome'] + 1
#unique policy space
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
unique_policy_dummies = data.frame(lme4::dummy(df$unique_policy_id))
df = cbind(df, unique_policy_dummies)
#simple OLS
unique_policies = names(unique_policy_dummies)
formula = as.formula(paste0("outcome","~",paste0(c(unique_policies,'year','age'),collapse = "+")))
OLS = estimatr::lm_robust(formula = formula, data = df)
OLS
arms = c('sms','incentive','information')
fes = c('year','age')
y = 'outcome'
grid_pval_OSE(data=df,arms=arms,fes=fes,y=y)
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.05 )
result$marginal_support
OLS
OLS$coefficients
hist(OLS$coefficients)
result$marginal_support
result$pools_summary
result$unique_policy
result$data
#simulate observations
n_obs = 1000
sms = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
incentive = c(0,1,2) %>% sample(.,replace=TRUE, n_obs)
information = c(0,1,2,3) %>% sample(.,replace=TRUE, n_obs)
df = data.frame(outcome=0, sms=sms, incentive=incentive, information=information )
#define the true outcome
df[(df$information == 0) & (df$incentive >=1),'outcome'] = 1
df[(df$information >= 1) & (df$incentive ==1),'outcome'] = 2.5
df[(df$information >= 1) & (df$incentive ==2),'outcome'] = 4.5
#add random noise
df$outcome = df$outcome + rnorm(n_obs, mean = 0 , sd = 2)
#fixed effects
df$year = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df$age  = c(0,1) %>% sample(.,replace=TRUE, n_obs)
df[df$year == 1,'outcome'] = df[df$year == 1,'outcome'] + 2
df[df$age  == 1,'outcome'] = df[df$age  == 1,'outcome'] + 1
#unique policy space
df$unique_policy_id = as.numeric(factor(paste0(df$sms, df$incentive, df$information)))
#
arms = c('sms','incentive','information')
fes = c('year','age')
y = 'outcome'
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.05 )
result$data
result$pooled_ols
result$winners_effect
plot_pval_OSE(data=df,arms=arms,fes=fes,y=y,scale=FALSE,compare_to_zero=FALSE)
grid_pval_MSE(data=df,arms=arms,fes=fes,y=y)
plot_pval_MSE(data=df,arms=arms,fes=fes,y=y,scale=FALSE,compare_to_zero=FALSE)
result = do_TVA(data = df, arms = arms, fes = fes, y = y, estimation_function_name = 'pval_MSE', cutoff = 1e-12 )
result = do_TVA(data = df, arms = arms, fes = fes, y = y, estimation_function_name = 'pval_MSE', cutoff = 1e-10 )
result$marginal_support
#document
path_SY="C:/Users/s.yaspo/Dropbox/Smart Pooling and Pruning/Package/TVA"
setwd(path_SY)
document()
result$marginal_support
:
:
:
#document
path_SY="C:/Users/s.yaspo/Dropbox/Smart Pooling and Pruning/Package/TVA"
setwd(path_SY)
document()
#Install the actual package
install_github('SimonYFR/TVA')
library('TVA')
result = do_TVA(data = df, arms = arms, fes = fes, y = y, cutoff = 0.05 )
result$marginal_support
result$pools_summary
result$unique_policy
result$fes_support
result$pooled_ols
result$winners_effect
